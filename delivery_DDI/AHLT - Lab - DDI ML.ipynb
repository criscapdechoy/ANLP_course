{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHLT - Lab - DDI ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Ricard Monge (group 12) and Cristina Capdevila (group 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the deliverables for the AHLT Lab DDI Machine Learning assignment.\n",
    "The notebook contains the following sections:\n",
    "\n",
    "- [Feature extractor function *extract features*](#features)\n",
    "    - [Depdency tree utility functions](#dependency)\n",
    "- [Learner function *learner*](#learner)\n",
    "    - [Get features and labels utility function](#get_features)\n",
    "- [Classifier function *classifier*](#classifier)\n",
    "    - [Output generator utility function](#output)\n",
    "- [Model comparison on Devel dataset](#dev_table_results)\n",
    "- [Model comparison on Test dataset](#test_table_results)\n",
    "- [Conclusion](#conclusion)\n",
    "\n",
    "We do not present the *analyze* function as it is the same as for the previous task *DDI_baseline*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='features'></a>\n",
    "## Feature extractor function *extract_features*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve upon the baseline DDI classification we devise a set of features with used to train the classifiers to detect Drug Drug Interactions (DDI).\n",
    "\n",
    "We employ a set of utility functions to extract information from the sentence analysis depdenency tree, [see here](#dependency).\n",
    "\n",
    "Finally, we come up with 5 types of features:\n",
    "\n",
    "- **Lemma features**, which relate to the appearence of certain lemmas inside the sentence's tree. For instance the appearance of specific lemmas associated with each DDI type, the appearence of modal verbs (characteristic of advise DDI) or the relation with each entitiy ancestor verb with the DDI type assocated lemmas.\n",
    "\n",
    "- **Dependency features**, which relate to the dependencies on the dependency tree associated with each entity and its ancestors. For instance, which dependency the entity has with their head, i.e. entities which are direct obejcts *dobj* nominal subjects *nsubj*, etc or the string of connected depdencies of the entity until the root of the sentence.\n",
    "\n",
    "- **Common ancestor features**, which relate to the properties of the first common node in each entity's ancestors, such as its dependencies and tags, or its distance to the entities and distance to the root node.\n",
    "\n",
    "- **Tree addres features**, which check the existence of certain tree relationships withtin the entity, such as entities wich act as a direct object related to entites that act as a nominal modifier, which may be effects/mechanics DDI characteristics.\n",
    "\n",
    "- **NER features**, features related to the properties of the entity's lemma, such as the 2 or 3 prefix/sufix or the jaccard or edit distance between entities. This could help identify the types of drugs involved and thus the DDI.\n",
    "\n",
    "Given that the **MaxEnt** classifier allows for selection of feature columns on training, we decide to use for it only a subset of the features presented. We specified the final selected features in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(analysis, entities, e1, e2):\n",
    "    \"\"\"\n",
    "    Extract Features.\n",
    "    Function which receives an analyzed sentence tree, the entities\n",
    "    present in the sentence, and the ids of the two target entities and returns\n",
    "    a list of features to pass to a ML model to predict DDI.\n",
    "    Args:\n",
    "        - analysis: DependencyGraph object instance with sentence parsed\n",
    "            information.\n",
    "        - entities: dictionary of entities indexed by id with offset as value.\n",
    "        - e1: string with id of the first entity to consider.\n",
    "        - e2: string with id of the second entity to consider.\n",
    "    Return:\n",
    "        - feats: list of features extracted from the tree and e1, e2.\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "\n",
    "    # Get entity nodes from tree\n",
    "    n1 = get_entity_node(analysis, entities, e1)\n",
    "    n2 = get_entity_node(analysis, entities, e2)\n",
    "\n",
    "    # Get verb ancestor from entities\n",
    "    v1 = get_verb_ancestor(analysis, n1)\n",
    "    v2 = get_verb_ancestor(analysis, n2)\n",
    "\n",
    "    # Get ancestors nodes list for entity nodes and verb nodes\n",
    "    ance1 = get_ancestors(analysis, n1)\n",
    "    ance2 = get_ancestors(analysis, n2)\n",
    "    ancev1 = get_ancestors(analysis, v1)\n",
    "    ancev2 = get_ancestors(analysis, v2)\n",
    "\n",
    "    # DDI-type characteristic lemmas\n",
    "    advise_lemmas = [\"administer\", \"use\", \"recommend\", \"consider\", \"approach\",\n",
    "                     \"avoid\", \"monitor\", \"advise\", \"require\", \"contraindicate\"]\n",
    "    effect_lemmas = [\"increase\", \"report\", \"potentiate\", \"enhance\", \"decrease\",\n",
    "                     \"include\", \"result\", \"reduce\", \"occur\", \"produce\",\n",
    "                     \"prevent\", \"effect\"]\n",
    "    int_lemmas = [\"interact\", \"interaction\"]\n",
    "    mechanism_lemmas = [\"reduce\", \"increase\", \"decrease\"]\n",
    "    \n",
    "    # Mix lemmas\n",
    "    mix_lemmas = list(set(\n",
    "        advise_lemmas + effect_lemmas + int_lemmas + mechanism_lemmas))\n",
    "    \n",
    "    # Modal verbs lemmas\n",
    "    modal_vb = [\"can\", \"could\", \"may\", \"might\", \"must\", \"will\", \"would\",\n",
    "                \"shall\", \"should\"]\n",
    "\n",
    "    # Modal verbs and DDI-type lemmas present in sentence\n",
    "    modal_present = check_lemmas(analysis, modal_vb)\n",
    "    lemma_present = check_lemmas(analysis, mix_lemmas)\n",
    "    advise_present = check_lemmas(analysis, advise_lemmas)\n",
    "    effect_present = check_lemmas(analysis, effect_lemmas)\n",
    "    int_present = check_lemmas(analysis, int_lemmas)\n",
    "    mechanism_present = check_lemmas(analysis, effect_lemmas)\n",
    "\n",
    "    # e1<-*-VB Verb is part DDI-type lemmas\n",
    "    advise_v1 = True if v1[\"lemma\"] in advise_lemmas else \"null\"\n",
    "    effect_v1 = True if v1[\"lemma\"] in effect_lemmas else \"null\"\n",
    "    int_v1 = True if v1[\"lemma\"] in int_lemmas else \"null\"\n",
    "    mechanism_v1 = True if v1[\"lemma\"] in mechanism_lemmas else \"null\"\n",
    "    # e2<-*-VB Verb is part DDI-type lemmas\n",
    "    advise_v2 = True if v2[\"lemma\"] in advise_lemmas else \"null\"\n",
    "    effect_v2 = True if v2[\"lemma\"] in effect_lemmas else \"null\"\n",
    "    int_v2 = True if v2[\"lemma\"] in int_lemmas else \"null\"\n",
    "    mechanism_v2 = True if v2[\"lemma\"] in mechanism_lemmas else \"null\"\n",
    "\n",
    "\n",
    "    # Check if entities hang from the same verb\n",
    "    v1_lemma = v1[\"lemma\"]  # NOT USED\n",
    "    v2_lemma = v2[\"lemma\"]  # NOT USED\n",
    "    v1_equal_v2 = v1 == v2\n",
    "\n",
    "    # Get head dependencies\n",
    "    e1_rel = n1[\"rel\"]\n",
    "    e2_rel = n2[\"rel\"]\n",
    "    v1_rel = v1[\"rel\"]\n",
    "    v2_rel = v2[\"rel\"]\n",
    "\n",
    "    # Get node dependencies from all its ancestors\n",
    "    e1_deps = \"_\".join(n1[\"deps\"].keys()) if len(n1[\"deps\"]) else \"null\"\n",
    "    e2_deps = \"_\".join(n2[\"deps\"].keys()) if len(n2[\"deps\"]) else \"null\"\n",
    "    v1_deps = \"_\".join(v1[\"deps\"].keys()) if len(v1[\"deps\"]) else \"null\"\n",
    "    v2_deps = \"_\".join(v2[\"deps\"].keys()) if len(v2[\"deps\"]) else \"null\"\n",
    "    ance1_deps = \"_\".join([a[\"rel\"] for a in ance1]) if len(ance1) else \"null\"\n",
    "    ance2_deps = \"_\".join([a[\"rel\"] for a in ance2]) if len(ance2) else \"null\"\n",
    "\n",
    "    # Get node order\n",
    "    e1_over_e2 = n1 in ance2\n",
    "    e2_over_e1 = n2 in ance1  # NOT USED\n",
    "    v1_over_v2 = v1 in ancev2\n",
    "    v2_over_v1 = v2 in ancev1\n",
    "\n",
    "    # Common ancestor features\n",
    "    common = ([n for n in ance1 if n in ance2] if len(ance1) > len(ance2) else\n",
    "              [n for n in ance2 if n in ance1])\n",
    "    common_rel = common[0][\"rel\"] if len(common) else \"null\"\n",
    "    common_deps = (\"_\".join(common[0][\"deps\"].keys())\n",
    "                   if len(common) and len(common[0][\"deps\"]) else \"null\")\n",
    "    common_tag = common[0][\"tag\"] if len(common) else \"null\"\n",
    "    common_tag = dict_tags[common_tag]\n",
    "    common_dist_root = (len(ance1) - 1 - ance1.index(common[0])\n",
    "                        if len(common) else 99)\n",
    "    common_dist_e1 = ance1.index(common[0]) if len(common) else 99\n",
    "    common_dist_e2 = ance2.index(common[0]) if len(common) else 99\n",
    "\n",
    "    # Common ancestor son's rel for each entity's branch\n",
    "    common_dep11_rel = (\n",
    "        ance1[ance1.index(common[0]) - 1][\"rel\"]\n",
    "        if len(common) and ance1.index(common[0]) > 0 else \"null\")\n",
    "    common_dep12_rel = (\n",
    "        ance1[ance1.index(common[0]) - 2][\"rel\"]\n",
    "        if len(common) and ance1.index(common[0]) > 1 else \"null\")\n",
    "    common_dep13_rel = (\n",
    "        ance1[ance1.index(common[0]) - 3][\"rel\"]\n",
    "        if len(common) and ance1.index(common[0]) > 2 else \"null\")\n",
    "    common_dep21_rel = (\n",
    "        ance2[ance2.index(common[0]) - 1][\"rel\"]\n",
    "        if len(common) and ance2.index(common[0]) > 0 else \"null\")\n",
    "    common_dep22_rel = (\n",
    "        ance2[ance2.index(common[0]) - 2][\"rel\"]\n",
    "        if len(common) and ance2.index(common[0]) > 1 else \"null\")\n",
    "    common_dep23_rel = (\n",
    "        ance2[ance2.index(common[0]) - 3][\"rel\"]\n",
    "        if len(common) and ance2.index(common[0]) > 2 else \"null\")\n",
    "\n",
    "    # Common ancestor son's tag for each entity's branch\n",
    "    common_dep11_tag = (\n",
    "        dict_tags[ance1[ance1.index(common[0]) - 1][\"tag\"]]\n",
    "        if len(common) and ance1.index(common[0]) > 0 else \"null\")\n",
    "\n",
    "    common_dep22_tag = (\n",
    "        dict_tags[ance2[ance2.index(common[0]) - 2][\"tag\"]]\n",
    "        if len(common) and ance2.index(common[0]) > 1 else \"null\")\n",
    "\n",
    "    # Tree address features\n",
    "    # e1<-conj-x<-dobj-VB-nmod->e2\n",
    "    e2_nmod = get_dependency_address(v2, \"nmod\") == n2[\"address\"]\n",
    "    x_dobj = get_dependency_address(v1, \"dobj\")\n",
    "    nx = analysis.nodes[x_dobj] if x_dobj != -1 else v1\n",
    "    e1_conj_dobj = get_dependency_address(nx, \"conj\") == n1[\"address\"]\n",
    "    e1_conj_dobj_nmod_e2 = e1_conj_dobj and e2_nmod  # NOT USED\n",
    "\n",
    "    # NER features\n",
    "        \n",
    "    # Entity lemma features\n",
    "    lemma1 = str(n1[\"lemma\"])  # NOT USED\n",
    "    lemma2 = str(n2[\"lemma\"])  # NOT USED\n",
    "    \n",
    "    # 3-Prefix/Suffix from lemma\n",
    "    pre3_1 = lemma1[:3].lower()\n",
    "    pre3_2 = lemma2[:3].lower()\n",
    "    suf3_1 = lemma1[-3:].lower()\n",
    "    suf3_2 = lemma2[-3:].lower()\n",
    "    \n",
    "    # Number of capitals in token\n",
    "    capitals1 = sum(i.isupper() for i in lemma1)  # NOT USED\n",
    "    capitals2 = sum(i.isupper() for i in lemma2)  # NOT USED\n",
    "\n",
    "    # Gather variables\n",
    "    feats = [\n",
    "        modal_present,  \n",
    "        lemma_present,\n",
    "        advise_present,\n",
    "        effect_present,\n",
    "        int_present,\n",
    "        mechanism_present,  \n",
    "        advise_v1,\n",
    "        effect_v1,\n",
    "        int_v1,\n",
    "        mechanism_v1,\n",
    "        advise_v2,  \n",
    "        effect_v2,\n",
    "        int_v2,\n",
    "        mechanism_v2,\n",
    "        v1_equal_v2,\n",
    "        e1_rel,\n",
    "        e2_rel,\n",
    "        v1_rel,\n",
    "        v2_rel,\n",
    "        e1_deps,  \n",
    "        e2_deps,\n",
    "        e1_over_e2,\n",
    "        v1_over_v2,\n",
    "        v2_over_v1,\n",
    "        common_rel,  \n",
    "        common_tag,\n",
    "        common_dist_root,\n",
    "        common_dist_e1,\n",
    "        common_dist_e2,\n",
    "        common_deps, \n",
    "        common_dep11_rel,\n",
    "        common_dep12_rel,\n",
    "        common_dep13_rel,\n",
    "        common_dep21_rel,\n",
    "        common_dep22_rel, \n",
    "        common_dep23_rel,\n",
    "        common_dep11_tag,\n",
    "        common_dep22_tag,\n",
    "        v1_deps,\n",
    "        v2_deps,  \n",
    "        ance1_deps,\n",
    "        ance2_deps,\n",
    "        pre3_1,\n",
    "        pre3_2,\n",
    "        suf3_1,\n",
    "        suf3_2,\n",
    "    ]\n",
    "    # Turn variables f to categorical var_i=f\n",
    "    feats = [f\"var_{i}={f}\" for i, f in enumerate(feats)]\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dependency\"></a>\n",
    "### Depdency tree utility functions\n",
    "\n",
    "In order to analyse and extract the mentioend features from the dependency tree we build a series of utility functions to extract relations:\n",
    "\n",
    "- **Get entity node** function which retrieves the node corresponding with a given entity.\n",
    "\n",
    "- **Get verb ancestor** function which retrieves the first ancestor of type verb for a given entity and a given sentence analysis.\n",
    "\n",
    "- **Get dependency address** function which returns the address of a certain dependency for a given node, or -1 if the node has no such dependency.\n",
    "\n",
    "- **Check lemmas** function which checks if the words in the sentence contain the given lemmas, and returns the found lemma with the highest position in the depdency tree.\n",
    "\n",
    "- **Get ancestors** function which retrieves the list of ancestor nodes from the given node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_node(analysis, entities, entity):\n",
    "    \"\"\"\n",
    "    Get Entity Node.\n",
    "    Function which finds the node in the Dependency Tree which corresponds to\n",
    "    the root of the entity.\n",
    "    Args:\n",
    "        - analysis: DependencyTree object instance with sentence analysis.\n",
    "        - entities: dictionary with entity information.\n",
    "        - entity: string with id of entity to get.\n",
    "    Returns:\n",
    "        - node: dictionary with node from DependencyTree.\n",
    "    \"\"\"\n",
    "    # Get nodes list\n",
    "    nodes = [analysis.nodes[k] for k in analysis.nodes]\n",
    "    ents = entities[entity][\"text\"].split()\n",
    "    # Capture possible tree nodes containing or that are contained in entity\n",
    "    possible = sorted(\n",
    "        [node for node in nodes if node[\"word\"] is not None and\n",
    "         any(ent in node[\"word\"] for ent in ents)],\n",
    "        key=lambda x: x[\"head\"])\n",
    "    node = possible[0] if len(possible) else nodes[0]\n",
    "    return node\n",
    "\n",
    "\n",
    "def get_verb_ancestor(analysis, node):\n",
    "    \"\"\"\n",
    "    Get Verb Ancestor.\n",
    "    Function which looks in the node's antecessor nodes inthe analysis tree\n",
    "    until it finds a verb VB, and returns such verb.\n",
    "    Args:\n",
    "        - analysis: DependencyTree object instance with sentence analysis.\n",
    "        - node: dictionary with node to start from.\n",
    "    Return:\n",
    "        - node: dictionary with verb antecessor node from DependencyTree.\n",
    "    \"\"\"\n",
    "    nodes = analysis.nodes\n",
    "    while node[\"tag\"] != \"TOP\" and \"VB\" not in node[\"tag\"]:\n",
    "        node = nodes[node[\"head\"]]\n",
    "        if not node[\"tag\"]:\n",
    "            break\n",
    "    return node\n",
    "\n",
    "\n",
    "def get_dependency_address(node, dependency):\n",
    "    \"\"\"\n",
    "    Get Dependency Address.\n",
    "    Function which returns the address of a given dependency for a given node,\n",
    "    or a non tractable value -1, which always evaluates to False in the\n",
    "    features. To use when extracting features.\n",
    "    Args:\n",
    "        - node: dictionary with node to look dependencies from.\n",
    "        - dependency: string with dependency name to look for in node.\n",
    "    Return:\n",
    "        - _: string with address of found dependency, or -1 if not found.\n",
    "    \"\"\"\n",
    "    dep = node[\"deps\"][dependency]\n",
    "    # If dependency exists, return address\n",
    "    # If dependency does not exist, return non-value\n",
    "    return dep[0] if len(dep) else -1\n",
    "\n",
    "\n",
    "def check_lemmas(analysis, lemmas):\n",
    "    \"\"\"\n",
    "    Check Lemmas.\n",
    "    Function which checks if the words in the sentence contain the given\n",
    "    lemmas. Then returns the tree-higher encountered lemma, or \"null\" if none\n",
    "    found.\n",
    "    Args:\n",
    "        - analysis: DependencyTree object instance with sentence analysis.\n",
    "        - lemmas: list of strings with lemmas to check.\n",
    "    Returns:\n",
    "        - _: string with present lemma or None.\n",
    "    \"\"\"\n",
    "    nds = analysis.nodes\n",
    "    present = [nds[n] for n in nds\n",
    "               if (nds[n][\"word\"] is not None and nds[n][\"lemma\"] in lemmas)]\n",
    "    present = sorted(present, key=lambda x: x[\"head\"])\n",
    "    # return present[0][\"lemma\"] if len(present) else \"null\"\n",
    "    return \"True\" if len(present) else \"False\"\n",
    "\n",
    "\n",
    "def get_ancestors(analysis, node):\n",
    "    \"\"\"\n",
    "    Get Ancestors.\n",
    "    Function which returns the given node's ancestor nodes.\n",
    "    Args:\n",
    "        - analysis: DependencyTree object instance with sentence analysis.\n",
    "        - node: dictionary with node to start from.\n",
    "    Return:\n",
    "        - node: dictionary with verb antecessor node from DependencyTree.\n",
    "    \"\"\"\n",
    "    ancs = []\n",
    "    nds = analysis.nodes\n",
    "    while node[\"tag\"] and node[\"tag\"] != \"TOP\":\n",
    "        ancs.append(node)\n",
    "        node = nds[node[\"head\"]]\n",
    "    return ancs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='learner'></a>\n",
    "## Learner function *learner*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learner function takes the generated training features and the gold class labels for each entity pair together with the selected **model** and trains the selected classifer, then saves it for later use.\n",
    "\n",
    "We decide to try four different classifiers, which we think are able to capture the relations between selected features to detect DDI and their types.\n",
    "\n",
    "- **Maximum Entropy classifier** (**MaxEnt**), using the [MEGAM](http://users.umiacs.umd.edu/~hal/megam/version0_3/) optimizer package through command line executable abd a subset of the features used for the other classifiers.\n",
    "\n",
    "- **Multi-layer Perceptron Classifier** (**MLP**), through its implementation in *Sklearn* Python package.\n",
    "   \n",
    "- **Support Vector Classification** (**SVC**), through its implementation in *Sklearn* Python package.\n",
    "\n",
    "- **Logistic Regression** (**LR**), through its implementation in *Sklearn* Python package.\n",
    "\n",
    "After trying different configurations for the different classifiers, we decide for each classifier a set of hyper-parameters that give best results for the Devel dataset. Similarly, for the MaxEnt classifier we select a subset of features. Furthermore, for the *Sklearn* classifiers, we use One-Hot-Encoding to turn the categorical features into binary sets of features.\n",
    "\n",
    "The learner function, as well as the later mentioned classifer function, uses the [get_features_labels](#get_features) utility function to extract the sentence and entity ids, the generated features and gold standard class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper-parameters\n",
    "random_seed = 10\n",
    "\n",
    "# MaxEnt params\n",
    "feat_col = \"4-10,12,16-46,48\"\n",
    "\n",
    "# MLP params\n",
    "hidden_layer_sizes = \n",
    "alpha = 1\n",
    "activation = \"relu\"\n",
    "solver = \"adam\"\n",
    "n_epochs = 100\n",
    "early_stopping = True\n",
    "verbose = False\n",
    "\n",
    "# LR params\n",
    "C = 1e6\n",
    "multi_class = 'ovr'\n",
    "penalty = 'l2'\n",
    "max_iter = 1000\n",
    "lr_solver = 'lbfgs'\n",
    "n_jobs = -1\n",
    "lr_verbose = 0\n",
    "\n",
    "def learner(model, feature_input, output_fn):\n",
    "    \"\"\"\n",
    "    Learner.\n",
    "    Function which calls the learner with a given feature filename and an\n",
    "    output filename to save model to.\n",
    "    Args:\n",
    "        - model: string with model type to use.\n",
    "        - feature_input: string with filename of the file to extract features\n",
    "            from to fit the model.\n",
    "        - output_fn: string with filename of output file for trained model.\n",
    "    \"\"\"\n",
    "    if model == \"MaxEnt\":\n",
    "        # MaxEnt learner flow\n",
    "        megam_features = f\"{tmp_path}/megam_train_features.dat\"\n",
    "        megam_model = f\"{output_fn}.megam\"\n",
    "        system(f\"cat {feature_input}  | cut -f {feat_col} > \\\n",
    "            {megam_features}\")\n",
    "        system(f\"./{megam} -quiet -nc -nobias multiclass \\\n",
    "            {megam_features} > {megam_model}\")\n",
    "\n",
    "    elif model == \"MLP\":\n",
    "        _, x_cat, y = get_features_labels(feature_input)\n",
    "        # OneHotEncode variables\n",
    "        encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        encoder.fit(x_cat)\n",
    "        x = encoder.transform(x_cat)\n",
    "        # Create MLP instance\n",
    "        model = MLPClassifier(\n",
    "            hidden_layer_sizes=hidden_layer_sizes,\n",
    "            activation=activation,\n",
    "            solver=solver,\n",
    "            max_iter=n_epochs,\n",
    "            early_stopping=early_stopping,\n",
    "            random_state=random_seed,\n",
    "            verbose=verbose)\n",
    "        # Train MLP instance\n",
    "        model.fit(x, y)\n",
    "        # Save model to pickle\n",
    "        with open(f\"{output_fn}.MLP\", \"wb\") as fp:\n",
    "            pickle.dump([model, encoder], fp)\n",
    "\n",
    "    elif model == \"SVC\":\n",
    "        _, x_cat, y = get_features_labels(feature_input)\n",
    "        # OneHotEncode variables\n",
    "        encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        encoder.fit(x_cat)\n",
    "        x = encoder.transform(x_cat)\n",
    "        # Create SVC instance\n",
    "        model = SVC(random_state=random_seed)\n",
    "        # Train SVC instance\n",
    "        model.fit(x, y)\n",
    "        # Save model to pickle\n",
    "        with open(f\"{output_fn}.SVC\", \"wb\") as fp:\n",
    "            pickle.dump([model, encoder], fp)\n",
    "\n",
    "    elif model == \"LR\":\n",
    "        _, x_cat, y = get_features_labels(feature_input)\n",
    "        # OneHotEncode variables\n",
    "        encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        encoder.fit(x_cat)\n",
    "        x = encoder.transform(x_cat)\n",
    "        # Create LR instance\n",
    "        model = LR(\n",
    "            C=C,\n",
    "            multi_class=multi_class,\n",
    "            penalty=penalty,\n",
    "            max_iter=max_iter,\n",
    "            solver=lr_solver,\n",
    "            random_state=random_seed,\n",
    "            n_jobs=n_jobs,\n",
    "            verbose=lr_verbose)\n",
    "        # Train LR instance\n",
    "        model.fit(x, y)\n",
    "        # Save model to pickle\n",
    "        with open(f\"{output_fn}.LR\", \"wb\") as fp:\n",
    "            pickle.dump([model, encoder], fp)\n",
    "\n",
    "    else:\n",
    "        print(f\"[ERROR] Model {model} not implemented\")\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='get_features'></a>\n",
    "### Get features and labels\n",
    "\n",
    "Utiltiy function to extract sentence id, entities id for each entity of a given pair, generated features and gold standard DDI type from the given **input** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_labels(input):\n",
    "    \"\"\"\n",
    "    Get Features & Labels.\n",
    "    Function which opens the given filename and extracts the feature and label\n",
    "    vectors, togehter with the sentence and pair entities ids.\n",
    "    Args:\n",
    "        - input: string with filename of file to extract features from.\n",
    "    Returns:\n",
    "        - ids: list of lists with sentence id and entity pairs ids.\n",
    "        - feats: list of lists with binary feature vector.\n",
    "        - labels: list of labels for each entity pair, for the trainer to use.\n",
    "    \"\"\"\n",
    "    with open(input, \"r\") as fp:\n",
    "        lines = fp.read()\n",
    "    pairs = [sent.split(\"\\t\") for sent in lines.split(\"\\n\")[:-1]]\n",
    "    ids = []\n",
    "    labels = []\n",
    "    feats = []\n",
    "    for p in pairs:\n",
    "        ids.append((p[0], p[1], p[2]))\n",
    "        labels.append(p[3])\n",
    "        feat = [elem.split(\"=\")[1] for elem in p[4:]]\n",
    "        feats.append(feat)\n",
    "    return ids, feats, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classifier'></a>\n",
    "## Classifier function *classifier*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier function takes the generated features for the data and the trained model, according to the **model** parameter and outputs the predictions given by the model. The different prediction formats of each model type are normalized into the same format and finally passed onto the [ouput_features](#output) function.\n",
    "\n",
    "This function uses the [get_features_labels](#get_features) utility function to extract the sentence and entity ids, the generated features and gold standard class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(model, feature_input, model_input, outputfile):\n",
    "    \"\"\"\n",
    "    Classifier.\n",
    "    Function which retrived a trainer model and predicts the output for a given\n",
    "    validation set features file, to print output to another file.\n",
    "    Args:\n",
    "        - model: string with model type to use.\n",
    "        - feature_input: string with filename of the file to extract features\n",
    "            from to validate the model.\n",
    "        - outputfile: string with filename of output file for validation\n",
    "            predictions.\n",
    "    \"\"\"\n",
    "    # Retrieve sentences, entities and feature vectos\n",
    "    ids, x, _ = get_features_labels(feature_input)\n",
    "    if model == \"MaxEnt\":\n",
    "        # MaxEnt classifier flow\n",
    "        megam_features = f\"{tmp_path}/megam_valid_features.dat\"\n",
    "        megam_predictions = f\"{tmp_path}/megam_predictions.dat\"\n",
    "        system(f\"cat {feature_input} | cut -f {feat_col} > \\\n",
    "            {megam_features}\")\n",
    "        # system(f\"cat {feature_input} | cut -f4- > \\\n",
    "        #     {megam_features}\")\n",
    "        system(f\"./{megam} -quiet -nc -nobias -predict {model_input}.megam \\\n",
    "            multiclass {megam_features} > {megam_predictions}\")\n",
    "        with open(megam_predictions, \"r\") as fp:\n",
    "            lines = fp.readlines()\n",
    "        predictions = [line.split(\"\\t\")[0] for line in lines]\n",
    "\n",
    "    elif model == \"MLP\":\n",
    "        # Retrieve model\n",
    "        with open(f\"{model_input}.MLP\", \"rb\") as fp:\n",
    "            model, encoder = pickle.load(fp)\n",
    "        # OneHotEncode variables\n",
    "        x_ = encoder.transform(x)\n",
    "        # Predict classes\n",
    "        predictions = model.predict(x_)\n",
    "\n",
    "    elif model == \"SVC\":\n",
    "        # Retrieve model\n",
    "        with open(f\"{model_input}.SVC\", \"rb\") as fp:\n",
    "            model, encoder = pickle.load(fp)\n",
    "        # OneHotEncode variables\n",
    "        x_ = encoder.transform(x)\n",
    "        # Predict classes\n",
    "        predictions = model.predict(x_)\n",
    "\n",
    "    elif model == \"GBC\":\n",
    "        # Retrieve model\n",
    "        with open(f\"{model_input}.GBC\", \"rb\") as fp:\n",
    "            model, encoder = pickle.load(fp)\n",
    "        # OneHotEncode variables\n",
    "        x_ = encoder.transform(x)\n",
    "        # Predict classes\n",
    "        predictions = model.predict(x_)\n",
    "\n",
    "    elif model == \"LR\":\n",
    "        # Retrieve model\n",
    "        with open(f\"{model_input}.LR\", \"rb\") as fp:\n",
    "            model, encoder = pickle.load(fp)\n",
    "        # OneHotEncode variables\n",
    "        x_ = encoder.transform(x)\n",
    "        # Predict classes\n",
    "        predictions = model.predict(x_)\n",
    "\n",
    "    else:\n",
    "        print(f\"[ERROR] Model {model} not implemented\")\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Ouput entites for each sentence\n",
    "    with open(outputfile, \"w\") as outf:\n",
    "        for (id, id_e1, id_e2), type in zip(ids, predictions):\n",
    "            output_ddi(id, id_e1, id_e2, type, outf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='output'></a>\n",
    "### Output generator utility function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function recieves the token list  **tokens** for each sentence, identified by the **id** parameter, the ids of each entity of the considered pairs (**e1**,**e2**) in the given sentence, their predicted classes **type** of interaction and the list of extracted **features**. Then it outputs the correspondng line to write in the output features file object **outf**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_features(id, e1, e2, type, features, out):\n",
    "    \"\"\"\n",
    "    Output Features.\n",
    "    Function which outputs to the given opened file object the entity pair\n",
    "    specified with the features extracted from their sentence.\n",
    "    Args:\n",
    "        - id: string with sentence id.\n",
    "        - e1: string with id of the first entity to consider.\n",
    "        - e2: string with id of the second entity to consider.\n",
    "        - type: string with gold class of DDI, for use in training.\n",
    "        - features: list of extracted features from sentence tree.\n",
    "        - outf: file object with opened file for writing output features.\n",
    "    \"\"\"\n",
    "    feature_str = \"\\t\".join(features)\n",
    "    txt = f\"{id}\\t{e1}\\t{e2}\\t{type}\\t{feature_str}\\n\"\n",
    "    out.write(txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dev_table_results'></a>\n",
    "## Model comparison  on Devel dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model comparison:\n",
    "\n",
    "|model|prec|recall|F1|\n",
    "|--|--|--|--|\n",
    "|MaxEnt|0.6452|0.3821|0.4800|\n",
    "|--|--|--|--|\n",
    "|**MLP**|**0.5891**|**0.4601**|**0.5166**|\n",
    "|--|--|--|--|\n",
    "|SVC|0.4936|0.3521|0.411|\n",
    "|--|--|--|--|\n",
    "|**LR**|**0.4905**|**0.5530**|**0.5199**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the **MLP** and **LR** models have the highest *F1* scores, with higher precision for the **MLP** and higher recall and slightly higher *F1* for the **LR** model.\n",
    "\n",
    "Conversely, the maximum precision score is achieved with the **MaxEnt** classifier.\n",
    "\n",
    "Here are the evaluator outputs for the four models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SCORES FOR THE GROUP: ML_MaxEnt RUN=1\n",
    "Gold Dataset: /Devel\n",
    "\n",
    "Partial Evaluation: only detection of DDI (regadless to the type)\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "216\t88\t268\t484\t0.7105\t0.4463\t0.5482\n",
    "\n",
    "\n",
    "Detection and Classification of DDI\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "158\t146\t326\t484\t0.5197\t0.3264\t0.401\n",
    "\n",
    "\n",
    "________________________________________________________________________\n",
    "\n",
    "SCORES FOR DDI TYPE\n",
    "Scores for ddi with type mechanism\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "38\t37\t163\t201\t0.5067\t0.1891\t0.2754\n",
    "\n",
    "\n",
    "Scores for ddi with type effect\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "72\t76\t90\t162\t0.4865\t0.4444\t0.4645\n",
    "\n",
    "\n",
    "Scores for ddi with type advise\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "47\t33\t72\t119\t0.5875\t0.395\t0.4724\n",
    "\n",
    "\n",
    "Scores for ddi with type int\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "1\t0\t1\t2\t1\t0.5\t0.6667\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "\tP\tR\tF1\n",
    "\t0.6452\t0.3821\t0.48\n",
    "________________________________________________________________________\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SCORES FOR THE GROUP: ML_MLP RUN=1\n",
    "Gold Dataset: /Devel\n",
    "\n",
    "Partial Evaluation: only detection of DDI (regadless to the type)\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "278\t211\t206\t484\t0.5685\t0.5744\t0.5714\n",
    "\n",
    "\n",
    "Detection and Classification of DDI\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "213\t276\t271\t484\t0.4356\t0.4401\t0.4378\n",
    "\n",
    "\n",
    "________________________________________________________________________\n",
    "\n",
    "SCORES FOR DDI TYPE\n",
    "Scores for ddi with type mechanism\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "63\t91\t138\t201\t0.4091\t0.3134\t0.3549\n",
    "\n",
    "\n",
    "Scores for ddi with type effect\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "101\t143\t61\t162\t0.4139\t0.6235\t0.4975\n",
    "\n",
    "\n",
    "Scores for ddi with type advise\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "48\t42\t71\t119\t0.5333\t0.4034\t0.4593\n",
    "\n",
    "\n",
    "Scores for ddi with type int\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "1\t0\t1\t2\t1\t0.5\t0.6667\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "\tP\tR\tF1\n",
    "\t0.5891\t0.4601\t0.5166\n",
    "________________________________________________________________________\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SCORES FOR THE GROUP: ML_SVC RUN=1\n",
    "Gold Dataset: /Devel\n",
    "\n",
    "Partial Evaluation: only detection of DDI (regadless to the type)\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "252\t80\t232\t484\t0.759\t0.5207\t0.6176\n",
    "\n",
    "\n",
    "Detection and Classification of DDI\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "217\t115\t267\t484\t0.6536\t0.4483\t0.5319\n",
    "\n",
    "\n",
    "________________________________________________________________________\n",
    "\n",
    "SCORES FOR DDI TYPE\n",
    "Scores for ddi with type mechanism\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "58\t35\t143\t201\t0.6237\t0.2886\t0.3946\n",
    "\n",
    "\n",
    "Scores for ddi with type effect\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "97\t55\t65\t162\t0.6382\t0.5988\t0.6178\n",
    "\n",
    "\n",
    "Scores for ddi with type advise\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "62\t25\t57\t119\t0.7126\t0.521\t0.6019\n",
    "\n",
    "\n",
    "Scores for ddi with type int\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "0\t0\t2\t2\t0\t0\t0\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "\tP\tR\tF1\n",
    "\t0.4936\t0.3521\t0.411\n",
    "________________________________________________________________________\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SCORES FOR THE GROUP: ML_LR RUN=1\n",
    "Gold Dataset: /Devel\n",
    "\n",
    "Partial Evaluation: only detection of DDI (regadless to the type)\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "251\t158\t233\t484\t0.6137\t0.5186\t0.5622\n",
    "\n",
    "\n",
    "Detection and Classification of DDI\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "192\t217\t292\t484\t0.4694\t0.3967\t0.43\n",
    "\n",
    "\n",
    "________________________________________________________________________\n",
    "\n",
    "SCORES FOR DDI TYPE\n",
    "Scores for ddi with type mechanism\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "53\t81\t148\t201\t0.3955\t0.2637\t0.3164\n",
    "\n",
    "\n",
    "Scores for ddi with type effect\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "91\t103\t71\t162\t0.4691\t0.5617\t0.5112\n",
    "\n",
    "\n",
    "Scores for ddi with type advise\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "46\t31\t73\t119\t0.5974\t0.3866\t0.4694\n",
    "\n",
    "\n",
    "Scores for ddi with type int\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "2\t2\t0\t2\t0.5\t1\t0.6667\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "\tP\tR\tF1\n",
    "\t0.4905\t0.553\t0.5199\n",
    "________________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='test_table_results'></a>\n",
    "## Model comparison  on Test-DDI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model comparison:\n",
    "\n",
    "|model|prec|recall|F1|\n",
    "|--|--|--|--|\n",
    "|**MaxEnt**|**0.5386**|**0.3231**|**0.4039**|\n",
    "|--|--|--|--|\n",
    "|MLP|0.3678|0.3823|0.3749|\n",
    "|--|--|--|--|\n",
    "|**SVC**|**0.6114**|**0.4013**|**0.4845**|\n",
    "|--|--|--|--|\n",
    "|LR|0.4489|0.3596|0.3993|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that opposite to the Devel dataset results, the **MaxEnt** and **SVC** models have the highest *F1* scores, with higher precision and *F1* for the **SVC**.\n",
    "\n",
    "Contrary, the models with higher *F1* score in the Devel dataset **MaxEnt** and **LR** have greater generalization error and thus much lower performance in the Test dataset. This shows these models were overfitted.\n",
    "\n",
    "Here are the evaluator outputs for the four models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SCORES FOR THE GROUP: ML_MaxEnt RUN=2\n",
    "Gold Dataset: /Test-DDI\n",
    "\n",
    "Partial Evaluation: only detection of DDI (regadless to the type)\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "426\t177\t553\t979\t0.7065\t0.4351\t0.5386\n",
    "\n",
    "\n",
    "Detection and Classification of DDI\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "296\t307\t683\t979\t0.4909\t0.3023\t0.3742\n",
    "\n",
    "\n",
    "________________________________________________________________________\n",
    "\n",
    "SCORES FOR DDI TYPE\n",
    "Scores for ddi with type mechanism\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "53\t53\t249\t302\t0.5\t0.1755\t0.2598\n",
    "\n",
    "\n",
    "Scores for ddi with type effect\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "125\t173\t235\t360\t0.4195\t0.3472\t0.3799\n",
    "\n",
    "\n",
    "Scores for ddi with type advise\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "78\t62\t143\t221\t0.5571\t0.3529\t0.4321\n",
    "\n",
    "\n",
    "Scores for ddi with type int\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "40\t19\t56\t96\t0.678\t0.4167\t0.5161\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "\tP\tR\tF1\n",
    "\t0.5386\t0.3231\t0.4039\n",
    "________________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SCORES FOR THE GROUP: ML_MLP RUN=2\n",
    "Gold Dataset: /Test-DDI\n",
    "\n",
    "Partial Evaluation: only detection of DDI (regadless to the type)\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "563\t533\t416\t979\t0.5137\t0.5751\t0.5427\n",
    "\n",
    "\n",
    "Detection and Classification of DDI\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "380\t716\t599\t979\t0.3467\t0.3882\t0.3663\n",
    "\n",
    "\n",
    "________________________________________________________________________\n",
    "\n",
    "SCORES FOR DDI TYPE\n",
    "Scores for ddi with type mechanism\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "92\t212\t210\t302\t0.3026\t0.3046\t0.3036\n",
    "\n",
    "\n",
    "Scores for ddi with type effect\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "163\t346\t197\t360\t0.3202\t0.4528\t0.3751\n",
    "\n",
    "\n",
    "Scores for ddi with type advise\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "90\t99\t131\t221\t0.4762\t0.4072\t0.439\n",
    "\n",
    "\n",
    "Scores for ddi with type int\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "35\t59\t61\t96\t0.3723\t0.3646\t0.3684\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "\tP\tR\tF1\n",
    "\t0.3678\t0.3823\t0.3749\n",
    "________________________________________________________________________\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SCORES FOR THE GROUP: ML_SVC RUN=2\n",
    "Gold Dataset: /Test-DDI\n",
    "\n",
    "Partial Evaluation: only detection of DDI (regadless to the type)\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "533\t155\t446\t979\t0.7747\t0.5444\t0.6395\n",
    "\n",
    "\n",
    "Detection and Classification of DDI\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "396\t292\t583\t979\t0.5756\t0.4045\t0.4751\n",
    "\n",
    "\n",
    "________________________________________________________________________\n",
    "\n",
    "SCORES FOR DDI TYPE\n",
    "Scores for ddi with type mechanism\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "92\t55\t210\t302\t0.6259\t0.3046\t0.4098\n",
    "\n",
    "\n",
    "Scores for ddi with type effect\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "161\t161\t199\t360\t0.5\t0.4472\t0.4721\n",
    "\n",
    "\n",
    "Scores for ddi with type advise\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "108\t59\t113\t221\t0.6467\t0.4887\t0.5567\n",
    "\n",
    "\n",
    "Scores for ddi with type int\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "35\t17\t61\t96\t0.6731\t0.3646\t0.473\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "\tP\tR\tF1\n",
    "\t0.6114\t0.4013\t0.4845\n",
    "________________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SCORES FOR THE GROUP: ML_LR RUN=2\n",
    "Gold Dataset: /Test-DDI\n",
    "\n",
    "Partial Evaluation: only detection of DDI (regadless to the type)\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "516\t349\t463\t979\t0.5965\t0.5271\t0.5597\n",
    "\n",
    "\n",
    "Detection and Classification of DDI\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "343\t522\t636\t979\t0.3965\t0.3504\t0.372\n",
    "\n",
    "\n",
    "________________________________________________________________________\n",
    "\n",
    "SCORES FOR DDI TYPE\n",
    "Scores for ddi with type mechanism\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "81\t180\t221\t302\t0.3103\t0.2682\t0.2877\n",
    "\n",
    "\n",
    "Scores for ddi with type effect\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "137\t250\t223\t360\t0.354\t0.3806\t0.3668\n",
    "\n",
    "\n",
    "Scores for ddi with type advise\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "87\t59\t134\t221\t0.5959\t0.3937\t0.4741\n",
    "\n",
    "\n",
    "Scores for ddi with type int\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "38\t33\t58\t96\t0.5352\t0.3958\t0.4551\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "\tP\tR\tF1\n",
    "\t0.4489\t0.3596\t0.3993\n",
    "________________________________________________________________________\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, we would recommend to use **MaxEnt** or the **SVC** classiier for further DDI detection with the selected features. They have been the models wich have presented less difference between the Devel and Test results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
